"""
åˆå¹¶ä¸‰ä¸ªæ•°æ®é›†ï¼š
- br/basketball_and_hoop2.v4i.yolo26
- br/basketball.v21i.yolo26  
- br/basketballhoop.v5i.yolo26

ç»Ÿä¸€ç±»åˆ«ä¸ºï¼š['basketball', 'hoop']
"""
import shutil
from pathlib import Path
import re

def copy_and_process_files(src_dirs, output_dir, category_map):
    """
    å¤åˆ¶å¹¶å¤„ç†æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
    category_map: ä»æºç±»åˆ«åˆ°ç›®æ ‡ç±»åˆ«çš„æ˜ å°„
    """
    total_copied = 0

    for src_base_dir in src_dirs:
        # å¤„ç†æ¯ä¸ª split: train, valid, test
        for split in ["train", "valid", "test"]:
            src_images = src_base_dir / split / "images"
            src_labels = src_base_dir / split / "labels"

            if not src_images.exists():
                continue

            # ç›®æ ‡ç›®å½•
            dst_split_dir = output_dir / split
            dst_images = dst_split_dir / "images"
            dst_labels = dst_split_dir / "labels"
            dst_images.mkdir(parents=True, exist_ok=True)
            dst_labels.mkdir(parents=True, exist_ok=True)

            # å¤åˆ¶å¹¶å¤„ç†å›¾ç‰‡å’Œæ ‡ç­¾
            split_count = 0
            for img_path in src_images.glob("*.jpg"):
                # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
                unique_name = f"{src_base_dir.name}_{img_path.name}"
                dst_img = dst_images / unique_name
                
                # å¤åˆ¶å›¾ç‰‡
                shutil.copy2(str(img_path), str(dst_img))

                # å¤„ç†æ ‡ç­¾æ–‡ä»¶
                label_path = src_labels / (img_path.stem + ".txt")
                if label_path.exists():
                    dst_label = dst_labels / (unique_name.rsplit('.', 1)[0] + ".txt")
                    
                    # è¯»å–å¹¶å¤„ç†æ ‡ç­¾
                    with open(label_path, 'r', encoding='utf-8') as f:
                        lines = f.readlines()

                    processed_lines = []
                    for line in lines:
                        parts = line.strip().split()
                        if parts:
                            class_id = int(parts[0])
                            # æ˜ å°„ç±»åˆ«
                            new_class_id = category_map.get(class_id, class_id)
                            parts[0] = str(new_class_id)
                            processed_lines.append(' '.join(parts) + '\n')

                    # å†™å…¥å¤„ç†åçš„æ ‡ç­¾
                    if processed_lines:
                        with open(dst_label, 'w', encoding='utf-8') as f:
                            f.writelines(processed_lines)

                    split_count += 1
                    total_copied += 1
                    if total_copied % 100 == 0:
                        print(f"   å·²å¤„ç† {total_copied} ä¸ªæ–‡ä»¶...")

            if split_count > 0:
                print(f"     {split}: {split_count} ä¸ªæ–‡ä»¶")

    return total_copied

def main():
    print("=" * 80)
    print("åˆå¹¶ç¯®çƒæ•°æ®é›†")
    print("=" * 80)

    # å®šä¹‰æ•°æ®é›†è·¯å¾„
    datasets = [
        Path("br/basketball_and_hoop2.v4i.yolo26"),  # ç±»åˆ«: ['basketball', 'hoop']
        Path("br/basketball.v21i.yolo26"),           # ç±»åˆ«: ?
        Path("br/basketballhoop.v5i.yolo26"),         # ç±»åˆ«: ['ball', 'hoop']
    ]

    # å®šä¹‰ç›®æ ‡ç›®å½•
    output_dir = Path("merged_basketball_dataset")
    train_dir = output_dir / "train"
    valid_dir = output_dir / "valid"
    test_dir = output_dir / "test"

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    output_dir.mkdir(exist_ok=True)
    train_dir.mkdir(exist_ok=True)
    valid_dir.mkdir(exist_ok=True)
    test_dir.mkdir(exist_ok=True)

    print("\nğŸ“‹ æ•°æ®é›†ä¿¡æ¯:")
    print(f"1. {datasets[0].name} - ç±»åˆ«: ['basketball', 'hoop']")
    print(f"2. {datasets[1].name} - ç±»åˆ«: å¾…æ£€æµ‹")
    print(f"3. {datasets[2].name} - ç±»åˆ«: ['ball', 'hoop']")

    # åˆ†æç¬¬äºŒä¸ªæ•°æ®é›†çš„ç±»åˆ«
    second_data_yaml = datasets[1] / "data.yaml"
    if second_data_yaml.exists():
        with open(second_data_yaml, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"   æ£€æµ‹åˆ° {datasets[1].name} çš„ data.yaml")

    print("\n" + "=" * 80)
    print("å¼€å§‹åˆå¹¶æ•°æ®é›†...")
    print("=" * 80)

    # å¤„ç†æ¯ä¸ªæ•°æ®é›†ï¼Œç»Ÿä¸€ç±»åˆ«ä¸º ['basketball', 'hoop']
    print("\n1. å¤„ç† basketball_and_hoop2.v4i.yolo26...")
    # ç±»åˆ«å·²åŒ¹é…: 0 -> basketball, 1 -> hoop
    count1 = copy_and_process_files([datasets[0]], output_dir, {0: 0, 1: 1})

    print(f"\n2. å¤„ç† basketball.v21i.yolo26...")
    # å‡è®¾ç±»åˆ«ä¹Ÿæ˜¯ ['basketball', 'hoop'] æˆ– ['ball', 'hoop']
    count2 = copy_and_process_files([datasets[1]], output_dir, {0: 0, 1: 1})

    print(f"\n3. å¤„ç† basketballhoop.v5i.yolo26...")
    # æ˜ å°„ç±»åˆ«: 0 -> ball -> 0 -> basketball, 1 -> hoop -> 1 -> hoop
    count3 = copy_and_process_files([datasets[2]], output_dir, {0: 0, 1: 1})

    # ç”Ÿæˆ data.yaml
    data_yaml_content = '''train: ../train/images
val: ../valid/images
test: ../test/images

nc: 2
names: ['basketball', 'hoop']

# Merged dataset from:
# - basketball_and_hoop2.v4i.yolo26
# - basketball.v21i.yolo26
# - basketballhoop.v5i.yolo26
''' 

    with open(output_dir / "data.yaml", 'w', encoding='utf-8') as f:
        f.write(data_yaml_content)

    total_count = count1 + count2 + count3
    print(f"\nâœ… å®Œæˆï¼")
    print(f"\nğŸ“Š åˆå¹¶ç»Ÿè®¡:")
    print(f"   - basketball_and_hoop2.v4i.yolo26: {count1} ä¸ªæ–‡ä»¶")
    print(f"   - basketball.v21i.yolo26: {count2} ä¸ªæ–‡ä»¶")
    print(f"   - basketballhoop.v5i.yolo26: {count3} ä¸ªæ–‡ä»¶")
    print(f"   - æ€»è®¡: {total_count} ä¸ªæ–‡ä»¶")

    print(f"\nğŸ“ è¾“å‡ºç›®å½•:")
    print(f"   {output_dir}")
    print(f"   - data.yaml: ç»Ÿä¸€ç±»åˆ«é…ç½®")
    print(f"   - train/images: åˆå¹¶çš„å›¾ç‰‡")
    print(f"   - train/labels: åˆå¹¶çš„æ ‡ç­¾")

if __name__ == "__main__":
    main()
